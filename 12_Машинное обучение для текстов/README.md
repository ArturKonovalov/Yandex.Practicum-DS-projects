# Проект для «Викишоп»

## Описание задачи:

Интернет-магазин «Викишоп» запускает новый сервис. Их пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. В нашем распоряжении набор данных с разметкой о токсичности правок.

## Цель исследования:  

Построить модель, классифицирующую комментарии на позитивные и негативные, со значением метрики качества `F1` не меньше 0.75. 
___
## Ход исследования:
1. Загрузим данные и проверим на наличие пропусков и дубликатов.
2. Удалим неинформативные признаки.
3. Проверим баланс классов.
4. Проведем лемматизацию и чистку текста.
5. Разделим данные на выборки.
6. Проведем углубленное исследование данных.
7. Создадим пайплайны для проверки нескольких способов предварительной подготовки корпуса:
* с использованием мешка слов и параметра TF-IDF
* с отсечением стоп-слов и без отсечения
8. Произведем их оценку метрикой качества на Логистической Регрессии и выберем лучший. 
9. Протестируем несколько, разных моделей и подберем гиперпараметры для лидера.
10. Проверим прогнозы лучшей модели на тестовой выборке.

## Таким образом, исследование пройдёт в три этапа:

1. Загрузка и подготовка данных.
2. Обучение моделей. 
3. Тестирование лучшей модели.
 ____
 Стек технологий и инструментов:
 `pandas` `numpy` `seaborn` `pyplot` `stopwords` `nltk` 
 
`WordNetLemmatizer` `word_tokenize` `WordCloud` `TfidfVectorizer` `CountVectorizer`
 
 `train_test_split` `cross_val_score` `RandomizedSearchCV` `LogisticRegression` `SGDClassifier`
 
 `DecisionTreeClassifier` `f1_score` `make_pipeline` `tqdm` `spacy` `poisson`
