# Отток клиентов

## Описание задачи:

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 
Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## Цель исследования:
* Спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. 
* Построить модель с предельно большим значением *F1*-меры, не менее 0.59

### Исследование пройдёт в 3 этапа:
1. Подготовка данных.
2. Исследование задачи.
3. Тестирование модели.

   
## Ход исследования:

*Этап 1. Подготовка данных:*
- Первым делом откроем датасет и изучим основные аспекты.
- Проверим правильность заполнения, наименования столбцов
- Продиагностируем данные на наличие пропусков и дубликатов.
- Так как "новых" данных предостовляться от заказчика не планируется, то разобьем информацию на три выборки:
   * `train` - обучающую. 
   * `valid` - валидационную или проверочную. 
   * `test` - тестовую (аналог новых данных).
- Проведем стандартизацию данных.
- Применим прямое кодирование.
- Исследуем данные на дисбаланс классов.
  ____
*Этап 2. Исследование задачи:*
- Исходя из задачи бинарной классификации рассмотрим три модели обучения:
   * Модель дерева решений.
   * Модель случайного леса.
   * Модель логистической регрессии.
- Дополнительно будем измерять *AUC-ROC*, сравнивать её значение с *F1*-мерой.
- Выберем модель с наилучшим показанием метрики качества `F1`.
- Также подберем наилучшие гиперпараметры для выбранной модели. 
  ____
*Этап 3. Тестирование модели:*
- Проверим модель на тестовой выборке и посмотрим на ее поведение.

_____
  Стек технологий и инструментов:
`pandas` `numpy` `pyplot` `train_test_split` `random` `shuffle`

`StandardScaler` `OneHotEncoder` `DecisionTreeClassifier` `RandomForestClassifier`

`LogisticRegression` `accuracy_score`, `f1_score` `roc_auc_score` `RandomizedSearchCV`
____
# Итоги исследования:
* Для борьбы с дисбалансом использовали:
  * downsampling
  * указание параметра class_weight = `balanced` (остановились на этом методе)
* Учитывая эти методы обучили, подобрали гиперпараметры и сравнили результаты у следующих моделей:
  * Логистической регрессии
  * Дерева решений
  * Случайного леса
 
* Лучшая модель `Случайный лес`, показатели:
  * n_estimators = `95`
  * max_depth = `12` 
  * F1 = `0.6097`
